{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"WEBSITE UNDER CONSTRUCTION TODO # Create content Create moaarr content","title":"Home"},{"location":"#todo","text":"Create content Create moaarr content","title":"TODO"},{"location":"3-nodes-swarm/","text":"Docker the Zerg way # For a resilient installation we are going to build a docker swarm of 3 master nodes with also a worker role. (In swarm node can be master or worker - the one running containers - or both) It's important to understand the split brain concept. In the following cluster a quorum have to be kept to assure things don't go sideways. For the quorum to be achieve you should have 2 master nodes up. This is true for Swarm and GlusterFS. Nodes gonna be called: swarm1, swarm2, swarm3 +----------------------+ | +----------------------+ | [Node #1] |10.0.0.51 | | | [Node #1] |10.0.0.52 | | swarm1.lab.local +----------+----------+ swarm2.lab.local | | | | | | +----------------------+ | +----------------------+ | | | +----------------------+ | | [Node #3] |10.0.0.53 | | | swarm3.lab.local +----------+ | | +----------------------+ Why Swarm ? Swarm is an orchestration tool directly provided into docker from the version 1.12. It is easy to use compare to Kubernetes and easier to maintain for a small team. Highly-available (can tolerate the failure of a single component) Scalable (can add resource or capacity as required) Portable (run it on your home today, run it in everywhere tomorrow) Automated (requires minimal care and feeding) Why GlusterFS ? While Docker Swarm is great for keeping containers running and providing scaling capabilities, it does lack direct integration of persistent storage accross nodes. This means if you actually want your containers to keep any data persistent across restarts , you need to provide shared storage to every docker node. This also means you shouldn't use docker volume declaration in you docker files. Installing the host component # Installation is based on a fresh Centos Stream minimal server and should be executed on all nodes.","title":"Architecture"},{"location":"3-nodes-swarm/#docker-the-zerg-way","text":"For a resilient installation we are going to build a docker swarm of 3 master nodes with also a worker role. (In swarm node can be master or worker - the one running containers - or both) It's important to understand the split brain concept. In the following cluster a quorum have to be kept to assure things don't go sideways. For the quorum to be achieve you should have 2 master nodes up. This is true for Swarm and GlusterFS. Nodes gonna be called: swarm1, swarm2, swarm3 +----------------------+ | +----------------------+ | [Node #1] |10.0.0.51 | | | [Node #1] |10.0.0.52 | | swarm1.lab.local +----------+----------+ swarm2.lab.local | | | | | | +----------------------+ | +----------------------+ | | | +----------------------+ | | [Node #3] |10.0.0.53 | | | swarm3.lab.local +----------+ | | +----------------------+ Why Swarm ? Swarm is an orchestration tool directly provided into docker from the version 1.12. It is easy to use compare to Kubernetes and easier to maintain for a small team. Highly-available (can tolerate the failure of a single component) Scalable (can add resource or capacity as required) Portable (run it on your home today, run it in everywhere tomorrow) Automated (requires minimal care and feeding) Why GlusterFS ? While Docker Swarm is great for keeping containers running and providing scaling capabilities, it does lack direct integration of persistent storage accross nodes. This means if you actually want your containers to keep any data persistent across restarts , you need to provide shared storage to every docker node. This also means you shouldn't use docker volume declaration in you docker files.","title":"Docker the Zerg way"},{"location":"3-nodes-swarm/#installing-the-host-component","text":"Installation is based on a fresh Centos Stream minimal server and should be executed on all nodes.","title":"Installing the host component"},{"location":"3-nodes-swarm/DockerSwarm/Installation/","text":"Docker the Zerg way # For a resilient installation we are going to build a docker swarm of 3 master nodes with also a worker role. (In swarm node can be master or worker - the one running containers - or both) It's important to understand the split brain concept. In the following cluster a quorum have to be kept to assure things don't go sideways. For the quorum to be achieve you should have 2 master nodes up. This is true for Swarm and GlusterFS. Nodes gonna be called: swarm1, swarm2, swarm3 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 Why Swarm ? Swarm is an orchestration tool directly provided into docker from the version 1.12. It is easy to use compare to Kubernetes and easier to maintain for a small team. Highly-available (can tolerate the failure of a single component) Scalable (can add resource or capacity as required) Portable (run it on your home today, run it in everywhere tomorrow) Automated (requires minimal care and feeding) Why Ceph ? While Docker Swarm is great for keeping containers running and providing scaling capabilities, it does lack direct integration of persistent storage accross nodes. This means if you actually want your containers to keep any data persistent across restarts of services, you need to provide a shared storage to every docker nodes. This also means you shouldn't use docker volume declaration in you docker files. Installing the host component # Installation is based on a fresh Centos Stream minimal server. Therefore, it is only adapted for CentOS installation, it may or may not work on other distribution. Docker swarm # Prerequise # 3 x nodes (bare-metal or VMs), each with: - A mainstream Linux OS (tested on either CentOS 8 Stream) - At least 2GB RAM - At least 50GB disk space (but it'll be tight) - Connectivity to each other within the same subnet, and on a low-latency link (i.e., no WAN links) Installing Docker and Docker compose # Remove runc # dnf remove runc Adding docker repo # dnf install -y yum-utils dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo dnf install docker-ce docker-ce-cli containerd.io Installing docker-compose # dnf install python3-pip pip3 install --upgrade pip pip3 install setuptools-rust pip3 install docker-compose Let's start the whale # systemctl enable docker --now And now create a zerg warm from it # From swarm1: # docker swarm init Swarm initialized: current node ( ksdjlqsldjqsd2516685485 ) is now a manager. To add a worker to this swarm, run the following command: docker swarm \\ join --token SWMTKN-1-5pykfhyfvtsij0tg4ewrtqk7hz2twuq21okeqv54p1gw2ufdde-814yer1z55vmyk2mwdhvjbob1 \\ 10 .0.0.51:2377 To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions. We are going to add the two other nodes as manager: docker swarm join-token manager To add a manager to this swarm, run the following command: docker swarm join --token SWMTKN-1-5pykfhyfvtsij0tg4ewrtqk7hz2twuq21okeqv54p1gw2ufdde-2k0vay9aub5eheikw7qi9v82o 10 .0.0.51:2377 Run the command provided on your other nodes to join them to the swarm as managers. After addition of a node, the output of docker node ls (on either host) should reflect all the nodes: # docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSION p424u0yvmu0vvc8nsnspv83zw * swarm1.lab.local Ready Active Leader 20 .10.6 kg6w6ucpb2jf8v8xqai23pv3a swarm2.lab.local Ready Active Reachable 20 .10.6 lam7mgs5wus40iaydvp8u3ss7 swarm3.lab.local Ready Active Reachable 20 .10.6 You are now ready to swarm. Official Documentation : https://docs.docker.com/engine/swarm/ Little Network tweak # When running Docker Swarm on RedHat or CentOS VMs under VMware you may run into issues with communication over the swarm node routing mesh. This issue is traced back to UDP packets being dropped by the source node. Disabling checksum offloading appears to resolve this issue. Run the following on your VMs: ethtool -K [ interface ] tx-checksum-ip-generic off cat > /etc/NetworkManager/dispatcher.d/pre-up.d/10-tx-checksum-ip-generic <<'EOF' ethtool -K ens192 tx-checksum-ip-generic off EOF chmod +x /etc/NetworkManager/dispatcher.d/pre-up.d/10-tx-checksum-ip-generic Note: [interface] is your network adaptater so change it accordingly. Firewalling # {.align-center} Base configuration # Activate firewalld, you may want to check in /etc/firewalld/zones/ to check what is going to happen ^^ . One issue happening quite often is when you changed the default ssh port. As the ssh service declared in /usr/lib/firewalld/services/ssh.xml is referencing to port 22. If it's the case, copy the service.xml into /etc/firewalld/service and change the port of it. (And yes, this happen to me a few times) systemctl enable firewalld --now Unmask the service if needed : systemctl unmask firewalld By default, firewalld is having a public zone created. This public zone allow the use of ssh, cockpit, dhcpv6-client. cat /etc/firewalld/zones/public.xml <?xml version=\"1.0\" encoding=\"utf-8\"?> <zone> <short> Public </short> <description> For use in public areas. You do not trust the other computers on networks to not harm your computer. Only selected incoming connections are accepted. </description> <service name= \"ssh\" /> <service name= \"dhcpv6-client\" /> <service name= \"cockpit\" /> </zone> If you don't use cockpit or dhcpv6-client, you can remove them from the configuration. For example to delete cockpit service: firewall-cmd --permamnent --zone = public --remove-service = cockpit firewall-cmd --reload Note here the parameters: --permanent: means the rules gonna last after service restart --zone: is used to indicate what zone should be modified, by default it's the public one --remove-service : remove the service declared in /etc/firewalld/services/ without the .xml ending firewall-cmd --reload is going to reload firewalld with latest configuration. Let's add some services firewall-cmd --permanent --zone = public --add-service = http firewall-cmd --permanent --zone = public --add-service = https firewall-cmd --reload We are going now to create a new zone representing the nodes of our cluster, and add sources to it (understand incoming traffic). firewall-cmd --permanent --new-zone = swarm firewall-cmd --permanent --zone = swarm --add-source = 10 .0.0.51 firewall-cmd --permanent --zone = swarm --add-source = 10 .0.0.52 firewall-cmd --permanent --zone = swarm --add-source = 10 .0.0.53 firewall-cmd --reload Let's check if sources where added firewall-cmd --zone = swarm --list-sources Ajouter les services n\u00e9cessaires au cluster : cp -a /usr/lib/firewalld/services/docker-swarm.xml /etc/firewalld/services/ firewall-cmd --zone = swarm --add-service = docker-swarm --permanent firewall-cmd --reload Docker Swarm # Let's add the service to the swarm zone: By default firewalld come bundled with some services. You can find them in /usr/lib/firewalld/services . I like to copy them in /etc/firewalld/services when I use them as it prevent it to be changed after an update. Firewalld prioritize service in \"/etc/firewalld/services/\" then in /usr/lib/firewalld/services . So let's copy the docker-swarm service: cp /usr/lib/firewalld/services/docker-swarm.xml /etc/firewalld/services/ cat /etc/firewalld/services/docker-swarm.xml <?xml version=\"1.0\" encoding=\"utf-8\"?> <service> <short> Docker integrated swarm mode </short> <description> Natively managed cluster of Docker Engines (>=1.12.0), where you deploy services. </description> <port port= \"2377\" protocol= \"tcp\" /> <port port= \"7946\" protocol= \"tcp\" /> <port port= \"7946\" protocol= \"udp\" /> <port port= \"4789\" protocol= \"udp\" /> <protocol value= \"esp\" /> </service> Then add it to the zone: firewall-cmd --permanent --zone = swarm --add-service = docker-swarm firewall-cmd --reload firewall-cmd --zone = swarm --list-services docker-swarm Now we did allow the port and protocols for the nodes to be used our cluster, and off course all those action have to be done on each host of the cluster. Ceph # While Docker Swarm is great for keeping containers running (and restarting those that fail), it does nothing for persistent storage. This means if you actually want your containers to keep any data persistent across restarts (hint: you do!), you need to provide shared storage to every docker node. Ceph is an open-source software (software-defined storage) storage platform, implements object storage on a single distributed computer cluster, and provides 3-in-1 interfaces for object-, block and file-level storage. Ceph aims primarily for completely distributed operation without a single point of failure, scalable to the exabyte level, and freely available. There are several different ways to install Ceph. Choose the method that best suits your needs. For recommendation on ceph documentation is used cephadm. Cephadm installs and manages a Ceph cluster using containers and systemd, with tight integration with the CLI and dashboard GUI. Note on Cephadm: - Only supports Octopus and newer releases. - Fully integrated with the new orchestration API and fully supports the new CLI and dashboard features to manage cluster deployment. - Requires container support (podman or docker) and Python 3. Prerequise # 3 x Virtual Machines (configured earlier), each with: Support for \"modern\" versions of Python and LVM At least 2GB RAM At least 50GB disk space (but it'll be tight) Connectivity to each other within the same subnet, and on a low-latency link (i.e., no WAN links) At least an additionnal disk dedicated to the Ceph OSD (add it to previous host if needed) Each node should have the IP of every other participating node hard-coded in /etc/hosts (including its own IP) Choose your first manager node # One of your nodes will become the cephadm \"master\" node. Although all nodes will participate in the Ceph cluster, the master node will be the node which we bootstrap ceph on. It's also the node which will run the Ceph dashboard, and on which future upgrades will be processed. It doesn't matter which node you pick, and the cluster itself will operate in the event of a loss of the master node (although you won't see the dashboard) Install cephadm on master node\u00b6 # Run the following on the master node: RELEASE = \"quincy\" # Use curl to fetch the most recent version of the standalone script curl --silent --remote-name --location https://raw.githubusercontent.com/ceph/ceph/ $RELEASE /src/cephadm/cephadm #Make the cephadm script executable: chmod +x cephadm # To install the packages that provide the cephadm command, run the following commands: ./cephadm add-repo --release $RELEASE ./cephadm install #Install ceph-common and Confirm that cephadm is now in your PATH by running which: dnf install -y ceph-common which cephadm Bootstrap new Ceph cluster # The first step in creating a new Ceph cluster is running the cephadm bootstrap command on the Ceph cluster\u2019s first host. The act of running the cephadm bootstrap command on the Ceph cluster\u2019s first host creates the Ceph cluster\u2019s first \u201cmonitor daemon\u201d, and that monitor daemon needs an IP address. You must pass the IP address of the Ceph cluster\u2019s first host to the ceph bootstrap command, so you\u2019ll need to know the IP address of that host. MYIP = ` ip route get 1 .1.1.1 | grep -oP 'src \\K\\S+' ` mkdir -p /etc/ceph cephadm bootstrap --mon-ip $MYIP This command will: Create a monitor and manager daemon for the new cluster on the local host. Generate a new SSH key for the Ceph cluster and add it to the root user\u2019s /root/.ssh/authorized_keys file. Write a copy of the public key to /etc/ceph/ceph.pub . Write a minimal configuration file to /etc/ceph/ceph.conf . This file is needed to communicate with the new cluster. Write a copy of the client.admin administrative (privileged!) secret key to /etc/ceph/ceph.client.admin.keyring . Add the _admin label to the bootstrap host. By default, any host with this label will (also) get a copy of /etc/ceph/ceph.conf and /etc/ceph/ceph.client.admin.keyring. Check Ceph dashboard, access IP address of ceph-01 https://192.168.1.231:8443/ and use credentials from the cephadm bootstrap output then set a new password Confirm that the ceph command is accessible with: ceph -v Result: ceph version 17 .2.1 ( ec95624474b1871a821a912b8c3af68f8f8e7aa1 ) quincy ( stable ) Check status of ceph cluster, OK for [HEALTH_WARN] because OSDs are not added yet ceph -s Result: cluster: id: 588df728-316c-11ec-b956-005056aea762 health: HEALTH_WARN OSD count 0 < osd_pool_default_size 3 services: mon: 1 daemons, quorum ceph-01 ( age 14m ) mgr: ceph-01.wgdjcn ( active, since 12m ) osd: 0 osds: 0 up, 0 in data: pools: 0 pools, 0 pgs objects: 0 objects, 0 B usage: 0 B used, 0 B / 0 B avail pgs: Verify containers are running for each service and check status for systemd service for each containers docker ps | grep ceph systemctl status ceph-* --no-pager Adding hosts to the cluster. # To add each new host to the cluster, perform two steps: # Install the cluster\u2019s public SSH key in the new host\u2019s root user\u2019s ssh-copy-id -f -i /etc/ceph/ceph.pub root@swarm2.lab.local ssh-copy-id -f -i /etc/ceph/ceph.pub root@swarm3.lab.local #Tell Ceph that the new node is part of the cluster, make sure python3 installed and available on new node ceph orch host add swarm2.lab.local ceph orch host add swarm3.lab.local #Check the added host ceph orch host ls Result: HOST ADDR LABELS STATUS swarm1 192 .168.1.231 _admin swarm2 192 .168.1.232 swarm3 192 .168.1.233 Deploy OSDs to the cluster # Run this command to display an inventory of storage devices on all cluster hosts: ceph orch device ls Result: Hostname Path Type Serial Size Health Ident Fault Available swarm1 /dev/sdb ssd 25G Unknown N/A N/A Yes swarm2 /dev/sdb ssd 25G Unknown N/A N/A Yes swarm3 /dev/sdb ssd 25G Unknown N/A N/A Yes Tell Ceph to consume any available and unused storage device execute ceph orch apply osd --all-available-devices ceph orch apply osd --all-available-devices ceph -s Result: cluster: id: 588df728-316c-11ec-b956-005056aea762 health: HEALTH_OK services: mon: 3 daemons, quorum swarm1,swarm2,swarm3 ( age 5m ) mgr: swarm1.wgdjcn ( active, since 41m ) , standbys: ceph-02.rmltzq osd: 9 osds: 0 up, 9 in ( since 10s ) data: pools: 0 pools, 0 pgs objects: 0 objects, 0 B usage: 0 B used, 0 B / 0 B avail pgs: ceph osd tree Result: ID CLASS WEIGHT TYPE NAME STATUS REWEIGHT PRI-AFF -1 0 .08817 root default -5 0 .02939 host swarm1 1 ssd 0 .00980 osd.0 up 1 .00000 1 .00000 -7 0 .02939 host swarm2 0 ssd 0 .00980 osd.1 up 1 .00000 1 .00000 -3 0 .02939 host swarm3 2 ssd 0 .00980 osd.3 up 1 .00000 1 .00000 Deploy ceph-mon (ceph monitor daemon) # Ceph-mon is the cluster monitor daemon for the Ceph distributed file system. One or more instances of ceph-mon form a Paxos part-time parliament cluster that provides extremely reliable and durable storage of cluster membership, configuration, and state. Add ceph-mon to all node using placement option ceph orch apply mon --placement = \"swarm1.lab.local,swarm2.lab.local,swarm3.lab.local\" ceph orch ps | grep mon Result: mon.swarm1 swarm1 running ( 63m ) 7m ago 63m 209M 2048M 16 .2.6 02a72919e474 952d7 mon.swarm2 swarm2 running ( 27m ) 7m ago 27m 104M 2048M 16 .2.6 02a72919e474 f2d22 mon.swarm3 swarm3 running ( 25m ) 7m ago 25m 104M 2048M 16 .2.6 02a72919e474 bcc00 Result: Deploy ceph-mgr (ceph manager daemon) # The Ceph Manager daemon (ceph-mgr) runs alongside monitor daemons, to provide additional monitoring and interfaces to external monitoring and management systems. ceph orch apply mgr --placement = \"swarm1.lab.local,swarm2.lab.local,swarm3.lab.local\" ceph orch ps | grep mgr Result: mgr.swarm1.wgdjcn swarm1 *:9283 running ( 64m ) 8m ago 64m 465M - 16 .2.6 02a72919e474 c58a64249f9b mgr.swarm2.rmltzq swarm2 *:8443,9283 running ( 29m ) 8m ago 29m 385M - 16 .2.6 02a72919e474 36f7f6a02896 mgr.swarm3.lhwjwd swarm3 *:8443,9283 running ( 7s ) 2s ago 6s 205M - 16 .2.6 02a72919e474 c740f964b2de Set _admin label on all nodes # The orchestrator supports assigning labels to hosts. Labels are free form and have no particular meaning by itself and each host can have multiple labels. They can be used to specify placement of daemons. But the _admin force the replication of change on ceph.conf to all node with this tag. Official note: By default, a ceph.conf file and a copy of the client.admin keyring are maintained in /etc/ceph on all hosts with the _admin label, which is initially applied only to the bootstrap host. We usually recommend that one or more other hosts be given the _admin label so that the Ceph CLI (e.g., via cephadm shell) is easily accessible on multiple hosts. To add the _admin label to additional host(s) ceph orch host label add swarm3.lab.local _admin ceph orch host label add swarm3.lab.local _admin Prepare for cephFS mount # It's now necessary to tranfer the following files to your other nodes, so that cephadm can add them to your cluster, and so that they'll be able to mount the cephfs when we're done: Path on master Path on non-master /etc/ceph/ceph.conf /etc/ceph/ceph.conf /etc/ceph/ceph.client.admin.keyring /etc/ceph/ceph.client.admin.keyring Setup CephFS # On the master node, create a cephfs volume in your cluster, by running ceph fs volume create data . Ceph will handle the necessary orchestration itself, creating the necessary pool, mds daemon, etc. You can watch the progress by running ceph fs ls (to see the fs is configured), and ceph -s to wait for HEALTH_OK Reproduce the following on each node: mkdir /mnt/swarm echo -e \" # Mount cephfs volume \\n swarm1.lab.local,swarm2.lab.local,swarm3.lab.local:/ /mnt/swarm ceph name=admin,noatime,_netdev 0 0\" >> /etc/fstab mount -a You can now play around and copy delete data on /mnt/swarm and check the replication accross the nodes. References # https://docs.ceph.com/en/latest/cephadm/install/","title":"Installation"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#docker-the-zerg-way","text":"For a resilient installation we are going to build a docker swarm of 3 master nodes with also a worker role. (In swarm node can be master or worker - the one running containers - or both) It's important to understand the split brain concept. In the following cluster a quorum have to be kept to assure things don't go sideways. For the quorum to be achieve you should have 2 master nodes up. This is true for Swarm and GlusterFS. Nodes gonna be called: swarm1, swarm2, swarm3 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 Why Swarm ? Swarm is an orchestration tool directly provided into docker from the version 1.12. It is easy to use compare to Kubernetes and easier to maintain for a small team. Highly-available (can tolerate the failure of a single component) Scalable (can add resource or capacity as required) Portable (run it on your home today, run it in everywhere tomorrow) Automated (requires minimal care and feeding) Why Ceph ? While Docker Swarm is great for keeping containers running and providing scaling capabilities, it does lack direct integration of persistent storage accross nodes. This means if you actually want your containers to keep any data persistent across restarts of services, you need to provide a shared storage to every docker nodes. This also means you shouldn't use docker volume declaration in you docker files.","title":"Docker the Zerg way"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#installing-the-host-component","text":"Installation is based on a fresh Centos Stream minimal server. Therefore, it is only adapted for CentOS installation, it may or may not work on other distribution.","title":"Installing the host component"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#docker-swarm","text":"","title":"Docker swarm"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#prerequise","text":"3 x nodes (bare-metal or VMs), each with: - A mainstream Linux OS (tested on either CentOS 8 Stream) - At least 2GB RAM - At least 50GB disk space (but it'll be tight) - Connectivity to each other within the same subnet, and on a low-latency link (i.e., no WAN links)","title":"Prerequise"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#installing-docker-and-docker-compose","text":"","title":"Installing Docker and Docker compose"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#remove-runc","text":"dnf remove runc","title":"Remove runc"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#adding-docker-repo","text":"dnf install -y yum-utils dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo dnf install docker-ce docker-ce-cli containerd.io","title":"Adding docker repo"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#installing-docker-compose","text":"dnf install python3-pip pip3 install --upgrade pip pip3 install setuptools-rust pip3 install docker-compose","title":"Installing docker-compose"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#lets-start-the-whale","text":"systemctl enable docker --now","title":"Let's start the whale"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#and-now-create-a-zerg-warm-from-it","text":"From swarm1: # docker swarm init Swarm initialized: current node ( ksdjlqsldjqsd2516685485 ) is now a manager. To add a worker to this swarm, run the following command: docker swarm \\ join --token SWMTKN-1-5pykfhyfvtsij0tg4ewrtqk7hz2twuq21okeqv54p1gw2ufdde-814yer1z55vmyk2mwdhvjbob1 \\ 10 .0.0.51:2377 To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions. We are going to add the two other nodes as manager: docker swarm join-token manager To add a manager to this swarm, run the following command: docker swarm join --token SWMTKN-1-5pykfhyfvtsij0tg4ewrtqk7hz2twuq21okeqv54p1gw2ufdde-2k0vay9aub5eheikw7qi9v82o 10 .0.0.51:2377 Run the command provided on your other nodes to join them to the swarm as managers. After addition of a node, the output of docker node ls (on either host) should reflect all the nodes: # docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSION p424u0yvmu0vvc8nsnspv83zw * swarm1.lab.local Ready Active Leader 20 .10.6 kg6w6ucpb2jf8v8xqai23pv3a swarm2.lab.local Ready Active Reachable 20 .10.6 lam7mgs5wus40iaydvp8u3ss7 swarm3.lab.local Ready Active Reachable 20 .10.6 You are now ready to swarm. Official Documentation : https://docs.docker.com/engine/swarm/","title":"And now create a zerg warm from it"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#little-network-tweak","text":"When running Docker Swarm on RedHat or CentOS VMs under VMware you may run into issues with communication over the swarm node routing mesh. This issue is traced back to UDP packets being dropped by the source node. Disabling checksum offloading appears to resolve this issue. Run the following on your VMs: ethtool -K [ interface ] tx-checksum-ip-generic off cat > /etc/NetworkManager/dispatcher.d/pre-up.d/10-tx-checksum-ip-generic <<'EOF' ethtool -K ens192 tx-checksum-ip-generic off EOF chmod +x /etc/NetworkManager/dispatcher.d/pre-up.d/10-tx-checksum-ip-generic Note: [interface] is your network adaptater so change it accordingly.","title":"Little Network tweak"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#firewalling","text":"{.align-center}","title":"Firewalling"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#base-configuration","text":"Activate firewalld, you may want to check in /etc/firewalld/zones/ to check what is going to happen ^^ . One issue happening quite often is when you changed the default ssh port. As the ssh service declared in /usr/lib/firewalld/services/ssh.xml is referencing to port 22. If it's the case, copy the service.xml into /etc/firewalld/service and change the port of it. (And yes, this happen to me a few times) systemctl enable firewalld --now Unmask the service if needed : systemctl unmask firewalld By default, firewalld is having a public zone created. This public zone allow the use of ssh, cockpit, dhcpv6-client. cat /etc/firewalld/zones/public.xml <?xml version=\"1.0\" encoding=\"utf-8\"?> <zone> <short> Public </short> <description> For use in public areas. You do not trust the other computers on networks to not harm your computer. Only selected incoming connections are accepted. </description> <service name= \"ssh\" /> <service name= \"dhcpv6-client\" /> <service name= \"cockpit\" /> </zone> If you don't use cockpit or dhcpv6-client, you can remove them from the configuration. For example to delete cockpit service: firewall-cmd --permamnent --zone = public --remove-service = cockpit firewall-cmd --reload Note here the parameters: --permanent: means the rules gonna last after service restart --zone: is used to indicate what zone should be modified, by default it's the public one --remove-service : remove the service declared in /etc/firewalld/services/ without the .xml ending firewall-cmd --reload is going to reload firewalld with latest configuration. Let's add some services firewall-cmd --permanent --zone = public --add-service = http firewall-cmd --permanent --zone = public --add-service = https firewall-cmd --reload We are going now to create a new zone representing the nodes of our cluster, and add sources to it (understand incoming traffic). firewall-cmd --permanent --new-zone = swarm firewall-cmd --permanent --zone = swarm --add-source = 10 .0.0.51 firewall-cmd --permanent --zone = swarm --add-source = 10 .0.0.52 firewall-cmd --permanent --zone = swarm --add-source = 10 .0.0.53 firewall-cmd --reload Let's check if sources where added firewall-cmd --zone = swarm --list-sources Ajouter les services n\u00e9cessaires au cluster : cp -a /usr/lib/firewalld/services/docker-swarm.xml /etc/firewalld/services/ firewall-cmd --zone = swarm --add-service = docker-swarm --permanent firewall-cmd --reload","title":"Base configuration"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#docker-swarm_1","text":"Let's add the service to the swarm zone: By default firewalld come bundled with some services. You can find them in /usr/lib/firewalld/services . I like to copy them in /etc/firewalld/services when I use them as it prevent it to be changed after an update. Firewalld prioritize service in \"/etc/firewalld/services/\" then in /usr/lib/firewalld/services . So let's copy the docker-swarm service: cp /usr/lib/firewalld/services/docker-swarm.xml /etc/firewalld/services/ cat /etc/firewalld/services/docker-swarm.xml <?xml version=\"1.0\" encoding=\"utf-8\"?> <service> <short> Docker integrated swarm mode </short> <description> Natively managed cluster of Docker Engines (>=1.12.0), where you deploy services. </description> <port port= \"2377\" protocol= \"tcp\" /> <port port= \"7946\" protocol= \"tcp\" /> <port port= \"7946\" protocol= \"udp\" /> <port port= \"4789\" protocol= \"udp\" /> <protocol value= \"esp\" /> </service> Then add it to the zone: firewall-cmd --permanent --zone = swarm --add-service = docker-swarm firewall-cmd --reload firewall-cmd --zone = swarm --list-services docker-swarm Now we did allow the port and protocols for the nodes to be used our cluster, and off course all those action have to be done on each host of the cluster.","title":"Docker Swarm"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#ceph","text":"While Docker Swarm is great for keeping containers running (and restarting those that fail), it does nothing for persistent storage. This means if you actually want your containers to keep any data persistent across restarts (hint: you do!), you need to provide shared storage to every docker node. Ceph is an open-source software (software-defined storage) storage platform, implements object storage on a single distributed computer cluster, and provides 3-in-1 interfaces for object-, block and file-level storage. Ceph aims primarily for completely distributed operation without a single point of failure, scalable to the exabyte level, and freely available. There are several different ways to install Ceph. Choose the method that best suits your needs. For recommendation on ceph documentation is used cephadm. Cephadm installs and manages a Ceph cluster using containers and systemd, with tight integration with the CLI and dashboard GUI. Note on Cephadm: - Only supports Octopus and newer releases. - Fully integrated with the new orchestration API and fully supports the new CLI and dashboard features to manage cluster deployment. - Requires container support (podman or docker) and Python 3.","title":"Ceph"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#prerequise_1","text":"3 x Virtual Machines (configured earlier), each with: Support for \"modern\" versions of Python and LVM At least 2GB RAM At least 50GB disk space (but it'll be tight) Connectivity to each other within the same subnet, and on a low-latency link (i.e., no WAN links) At least an additionnal disk dedicated to the Ceph OSD (add it to previous host if needed) Each node should have the IP of every other participating node hard-coded in /etc/hosts (including its own IP)","title":"Prerequise"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#choose-your-first-manager-node","text":"One of your nodes will become the cephadm \"master\" node. Although all nodes will participate in the Ceph cluster, the master node will be the node which we bootstrap ceph on. It's also the node which will run the Ceph dashboard, and on which future upgrades will be processed. It doesn't matter which node you pick, and the cluster itself will operate in the event of a loss of the master node (although you won't see the dashboard)","title":"Choose your first manager node"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#install-cephadm-on-master-node","text":"Run the following on the master node: RELEASE = \"quincy\" # Use curl to fetch the most recent version of the standalone script curl --silent --remote-name --location https://raw.githubusercontent.com/ceph/ceph/ $RELEASE /src/cephadm/cephadm #Make the cephadm script executable: chmod +x cephadm # To install the packages that provide the cephadm command, run the following commands: ./cephadm add-repo --release $RELEASE ./cephadm install #Install ceph-common and Confirm that cephadm is now in your PATH by running which: dnf install -y ceph-common which cephadm","title":"Install cephadm on master node\u00b6"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#bootstrap-new-ceph-cluster","text":"The first step in creating a new Ceph cluster is running the cephadm bootstrap command on the Ceph cluster\u2019s first host. The act of running the cephadm bootstrap command on the Ceph cluster\u2019s first host creates the Ceph cluster\u2019s first \u201cmonitor daemon\u201d, and that monitor daemon needs an IP address. You must pass the IP address of the Ceph cluster\u2019s first host to the ceph bootstrap command, so you\u2019ll need to know the IP address of that host. MYIP = ` ip route get 1 .1.1.1 | grep -oP 'src \\K\\S+' ` mkdir -p /etc/ceph cephadm bootstrap --mon-ip $MYIP This command will: Create a monitor and manager daemon for the new cluster on the local host. Generate a new SSH key for the Ceph cluster and add it to the root user\u2019s /root/.ssh/authorized_keys file. Write a copy of the public key to /etc/ceph/ceph.pub . Write a minimal configuration file to /etc/ceph/ceph.conf . This file is needed to communicate with the new cluster. Write a copy of the client.admin administrative (privileged!) secret key to /etc/ceph/ceph.client.admin.keyring . Add the _admin label to the bootstrap host. By default, any host with this label will (also) get a copy of /etc/ceph/ceph.conf and /etc/ceph/ceph.client.admin.keyring. Check Ceph dashboard, access IP address of ceph-01 https://192.168.1.231:8443/ and use credentials from the cephadm bootstrap output then set a new password Confirm that the ceph command is accessible with: ceph -v Result: ceph version 17 .2.1 ( ec95624474b1871a821a912b8c3af68f8f8e7aa1 ) quincy ( stable ) Check status of ceph cluster, OK for [HEALTH_WARN] because OSDs are not added yet ceph -s Result: cluster: id: 588df728-316c-11ec-b956-005056aea762 health: HEALTH_WARN OSD count 0 < osd_pool_default_size 3 services: mon: 1 daemons, quorum ceph-01 ( age 14m ) mgr: ceph-01.wgdjcn ( active, since 12m ) osd: 0 osds: 0 up, 0 in data: pools: 0 pools, 0 pgs objects: 0 objects, 0 B usage: 0 B used, 0 B / 0 B avail pgs: Verify containers are running for each service and check status for systemd service for each containers docker ps | grep ceph systemctl status ceph-* --no-pager","title":"Bootstrap new Ceph cluster"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#adding-hosts-to-the-cluster","text":"To add each new host to the cluster, perform two steps: # Install the cluster\u2019s public SSH key in the new host\u2019s root user\u2019s ssh-copy-id -f -i /etc/ceph/ceph.pub root@swarm2.lab.local ssh-copy-id -f -i /etc/ceph/ceph.pub root@swarm3.lab.local #Tell Ceph that the new node is part of the cluster, make sure python3 installed and available on new node ceph orch host add swarm2.lab.local ceph orch host add swarm3.lab.local #Check the added host ceph orch host ls Result: HOST ADDR LABELS STATUS swarm1 192 .168.1.231 _admin swarm2 192 .168.1.232 swarm3 192 .168.1.233","title":"Adding hosts to the cluster."},{"location":"3-nodes-swarm/DockerSwarm/Installation/#deploy-osds-to-the-cluster","text":"Run this command to display an inventory of storage devices on all cluster hosts: ceph orch device ls Result: Hostname Path Type Serial Size Health Ident Fault Available swarm1 /dev/sdb ssd 25G Unknown N/A N/A Yes swarm2 /dev/sdb ssd 25G Unknown N/A N/A Yes swarm3 /dev/sdb ssd 25G Unknown N/A N/A Yes Tell Ceph to consume any available and unused storage device execute ceph orch apply osd --all-available-devices ceph orch apply osd --all-available-devices ceph -s Result: cluster: id: 588df728-316c-11ec-b956-005056aea762 health: HEALTH_OK services: mon: 3 daemons, quorum swarm1,swarm2,swarm3 ( age 5m ) mgr: swarm1.wgdjcn ( active, since 41m ) , standbys: ceph-02.rmltzq osd: 9 osds: 0 up, 9 in ( since 10s ) data: pools: 0 pools, 0 pgs objects: 0 objects, 0 B usage: 0 B used, 0 B / 0 B avail pgs: ceph osd tree Result: ID CLASS WEIGHT TYPE NAME STATUS REWEIGHT PRI-AFF -1 0 .08817 root default -5 0 .02939 host swarm1 1 ssd 0 .00980 osd.0 up 1 .00000 1 .00000 -7 0 .02939 host swarm2 0 ssd 0 .00980 osd.1 up 1 .00000 1 .00000 -3 0 .02939 host swarm3 2 ssd 0 .00980 osd.3 up 1 .00000 1 .00000","title":"Deploy OSDs to the cluster"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#deploy-ceph-mon-ceph-monitor-daemon","text":"Ceph-mon is the cluster monitor daemon for the Ceph distributed file system. One or more instances of ceph-mon form a Paxos part-time parliament cluster that provides extremely reliable and durable storage of cluster membership, configuration, and state. Add ceph-mon to all node using placement option ceph orch apply mon --placement = \"swarm1.lab.local,swarm2.lab.local,swarm3.lab.local\" ceph orch ps | grep mon Result: mon.swarm1 swarm1 running ( 63m ) 7m ago 63m 209M 2048M 16 .2.6 02a72919e474 952d7 mon.swarm2 swarm2 running ( 27m ) 7m ago 27m 104M 2048M 16 .2.6 02a72919e474 f2d22 mon.swarm3 swarm3 running ( 25m ) 7m ago 25m 104M 2048M 16 .2.6 02a72919e474 bcc00 Result:","title":"Deploy ceph-mon (ceph monitor daemon)"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#deploy-ceph-mgr-ceph-manager-daemon","text":"The Ceph Manager daemon (ceph-mgr) runs alongside monitor daemons, to provide additional monitoring and interfaces to external monitoring and management systems. ceph orch apply mgr --placement = \"swarm1.lab.local,swarm2.lab.local,swarm3.lab.local\" ceph orch ps | grep mgr Result: mgr.swarm1.wgdjcn swarm1 *:9283 running ( 64m ) 8m ago 64m 465M - 16 .2.6 02a72919e474 c58a64249f9b mgr.swarm2.rmltzq swarm2 *:8443,9283 running ( 29m ) 8m ago 29m 385M - 16 .2.6 02a72919e474 36f7f6a02896 mgr.swarm3.lhwjwd swarm3 *:8443,9283 running ( 7s ) 2s ago 6s 205M - 16 .2.6 02a72919e474 c740f964b2de","title":"Deploy ceph-mgr (ceph manager daemon)"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#set-_admin-label-on-all-nodes","text":"The orchestrator supports assigning labels to hosts. Labels are free form and have no particular meaning by itself and each host can have multiple labels. They can be used to specify placement of daemons. But the _admin force the replication of change on ceph.conf to all node with this tag. Official note: By default, a ceph.conf file and a copy of the client.admin keyring are maintained in /etc/ceph on all hosts with the _admin label, which is initially applied only to the bootstrap host. We usually recommend that one or more other hosts be given the _admin label so that the Ceph CLI (e.g., via cephadm shell) is easily accessible on multiple hosts. To add the _admin label to additional host(s) ceph orch host label add swarm3.lab.local _admin ceph orch host label add swarm3.lab.local _admin","title":"Set _admin label on all nodes"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#prepare-for-cephfs-mount","text":"It's now necessary to tranfer the following files to your other nodes, so that cephadm can add them to your cluster, and so that they'll be able to mount the cephfs when we're done: Path on master Path on non-master /etc/ceph/ceph.conf /etc/ceph/ceph.conf /etc/ceph/ceph.client.admin.keyring /etc/ceph/ceph.client.admin.keyring","title":"Prepare for cephFS mount"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#setup-cephfs","text":"On the master node, create a cephfs volume in your cluster, by running ceph fs volume create data . Ceph will handle the necessary orchestration itself, creating the necessary pool, mds daemon, etc. You can watch the progress by running ceph fs ls (to see the fs is configured), and ceph -s to wait for HEALTH_OK Reproduce the following on each node: mkdir /mnt/swarm echo -e \" # Mount cephfs volume \\n swarm1.lab.local,swarm2.lab.local,swarm3.lab.local:/ /mnt/swarm ceph name=admin,noatime,_netdev 0 0\" >> /etc/fstab mount -a You can now play around and copy delete data on /mnt/swarm and check the replication accross the nodes.","title":"Setup CephFS"},{"location":"3-nodes-swarm/DockerSwarm/Installation/#references","text":"https://docs.ceph.com/en/latest/cephadm/install/","title":"References"},{"location":"3-nodes-swarm/DockerSwarm/Stacks/Portainer/","text":"Portainer # Portainer is a lightweight management UI which allows you to easily manage your different Docker environments (Docker hosts or Swarm clusters). Portainer is meant to be as simple to deploy as it is to use. It consists of a single container that can run on any Docker engine (can be deployed as Linux container or a Windows native container, supports other platforms too). Portainer allows you to manage all your Docker resources (containers, images, volumes, networks and more!) It is compatible with the standalone Docker engine and with Docker Swarm mode. Preparaton # Setup Docker Swarm # Deploying Portainer and the Portainer Agent to manage a Swarm cluster is easy! You can directly deploy Portainer as a service in your Docker cluster. Note that this method will automatically deploy a single instance of the Portainer Server, and deploy the Portainer Agent as a global service on every node in your cluster. # mkdir -p /mnt/configuration_data/compose_files/administration # curl -L https://downloads.portainer.io/portainer-agent-stack.yml -o mnt/configuration_data/compose_files/administration/portainer-agent-stack.yml Customisation # By default portainer stack is using a normal docker volume. So if the node where the container will run fail, then we lost the data. To counter this we are going to use a local file shared accross nodes by GlusterFS. Edit portainer-agent-stack.yml Change: portainer_data:/data for /mnt/docker_data/administration/portainer_data:/data Remove: volumes: portainer_data: The file should look like this (I added some notes as comment): version: '3.2' services: agent: image: portainer/agent volumes: - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes networks: - agent_network deploy: mode: global # Will be deploy on all nodes manager or worker accross the swarm. placement: constraints: [node.platform.os == linux] # Will only run on Linux OS. portainer: image: portainer/portainer-ce command: -H tcp://tasks.agent:9001 --tlsskipverify ports: - \"9000:9000\" - \"8000:8000\" volumes: - /mnt/docker_data/administration/portainer_data:/data networks: - agent_network deploy: mode: replicated replicas: 1 # Only one container of this type gonna run at a time. placement: constraints: [node.role == manager] # Will only be deployed on a manager node. networks: agent_network: driver: overlay attachable: true Setup data locations # One issue you gonna have with swarm is that it's not creating folder for declared volume on it's own so you will have to create it by yourself. # mkdir -p /mnt/docker_data/administration/portainer_data If like me you are using the same base directory for docker data, you can run this on the compose file to automatically build the folder. grep \"/mnt/docker_data\" /mnt/configuration_data/compose_files/administration/portainer-agent-stack.yml | awk -F \"- \" '{print $2'} | awk -F \":\" '{ system(\"mkdir -p \"$1\"\") }' This could be made as a command but I like to run first and echo instead of the \"mkdir -p\" to be sure I didn't made a mistake. Deploy Portainer stack # Deploy the Portainer stack by running docker stack deploy -c <path -to-docker-compose.yml> portainer Log into your new instance at any nodes on port 9000. You'll be prompted to set your admin user/password on first login. Start at \"Home\", and click on \"Primary\" to manage your swarm (you can manage multiple swarms via one Portainer instance using the agent Todo # Add image Add Some basic usage","title":"Portainer"},{"location":"3-nodes-swarm/DockerSwarm/Stacks/Portainer/#portainer","text":"Portainer is a lightweight management UI which allows you to easily manage your different Docker environments (Docker hosts or Swarm clusters). Portainer is meant to be as simple to deploy as it is to use. It consists of a single container that can run on any Docker engine (can be deployed as Linux container or a Windows native container, supports other platforms too). Portainer allows you to manage all your Docker resources (containers, images, volumes, networks and more!) It is compatible with the standalone Docker engine and with Docker Swarm mode.","title":"Portainer"},{"location":"3-nodes-swarm/DockerSwarm/Stacks/Portainer/#preparaton","text":"","title":"Preparaton"},{"location":"3-nodes-swarm/DockerSwarm/Stacks/Portainer/#setup-docker-swarm","text":"Deploying Portainer and the Portainer Agent to manage a Swarm cluster is easy! You can directly deploy Portainer as a service in your Docker cluster. Note that this method will automatically deploy a single instance of the Portainer Server, and deploy the Portainer Agent as a global service on every node in your cluster. # mkdir -p /mnt/configuration_data/compose_files/administration # curl -L https://downloads.portainer.io/portainer-agent-stack.yml -o mnt/configuration_data/compose_files/administration/portainer-agent-stack.yml","title":"Setup Docker Swarm"},{"location":"3-nodes-swarm/DockerSwarm/Stacks/Portainer/#customisation","text":"By default portainer stack is using a normal docker volume. So if the node where the container will run fail, then we lost the data. To counter this we are going to use a local file shared accross nodes by GlusterFS. Edit portainer-agent-stack.yml Change: portainer_data:/data for /mnt/docker_data/administration/portainer_data:/data Remove: volumes: portainer_data: The file should look like this (I added some notes as comment): version: '3.2' services: agent: image: portainer/agent volumes: - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes networks: - agent_network deploy: mode: global # Will be deploy on all nodes manager or worker accross the swarm. placement: constraints: [node.platform.os == linux] # Will only run on Linux OS. portainer: image: portainer/portainer-ce command: -H tcp://tasks.agent:9001 --tlsskipverify ports: - \"9000:9000\" - \"8000:8000\" volumes: - /mnt/docker_data/administration/portainer_data:/data networks: - agent_network deploy: mode: replicated replicas: 1 # Only one container of this type gonna run at a time. placement: constraints: [node.role == manager] # Will only be deployed on a manager node. networks: agent_network: driver: overlay attachable: true","title":"Customisation"},{"location":"3-nodes-swarm/DockerSwarm/Stacks/Portainer/#setup-data-locations","text":"One issue you gonna have with swarm is that it's not creating folder for declared volume on it's own so you will have to create it by yourself. # mkdir -p /mnt/docker_data/administration/portainer_data If like me you are using the same base directory for docker data, you can run this on the compose file to automatically build the folder. grep \"/mnt/docker_data\" /mnt/configuration_data/compose_files/administration/portainer-agent-stack.yml | awk -F \"- \" '{print $2'} | awk -F \":\" '{ system(\"mkdir -p \"$1\"\") }' This could be made as a command but I like to run first and echo instead of the \"mkdir -p\" to be sure I didn't made a mistake.","title":"Setup data locations"},{"location":"3-nodes-swarm/DockerSwarm/Stacks/Portainer/#deploy-portainer-stack","text":"Deploy the Portainer stack by running docker stack deploy -c <path -to-docker-compose.yml> portainer Log into your new instance at any nodes on port 9000. You'll be prompted to set your admin user/password on first login. Start at \"Home\", and click on \"Primary\" to manage your swarm (you can manage multiple swarms via one Portainer instance using the agent","title":"Deploy Portainer stack"},{"location":"3-nodes-swarm/DockerSwarm/Stacks/Portainer/#todo","text":"Add image Add Some basic usage","title":"Todo"},{"location":"3-nodes-swarm/DockerSwarm/Stacks/Shuffler/","text":"Shuffle # Shuffle is an Open Source SOAR I really appreciate as it does focus on CyberSecurity. To know more about it go there: https://medium.com/shuffle-automation Or there : Official Website Hi Frikky !!! Hoipefully, you will appreciate what you are seing here ^^ Preparaton # Setup data locations # Setup Docker Swarm # Deploying Portainer and the Portainer Agent to manage a Swarm cluster is easy! You can directly deploy Portainer as a service in your Docker cluster. Note that this method will automatically deploy a single instance of the Portainer Server, and deploy the Portainer Agent as a global service on every node in your cluster. # mkdir -p /mnt/configuration_data/compose_files/SOAR Customisation # At the time of this writing I may be the only one shufflying around with swarm :p So there is not yet a stack ready compose file. Let's create one /mnt/configuration_data/compose_files/SOAR/shuffle.stack.yml version: '3.3' services: backend: image: ghcr.io/frikky/shuffle-backend:0.8.74 environment: DATASTORE_EMULATOR_HOST: shuffle-database:8000 HTTPS_PROXY: '' HTTP_PROXY: '' ORG_ID: Shuffle SHUFFLE_APP_DOWNLOAD_LOCATION: https://github.com/frikky/shuffle-apps SHUFFLE_APP_FORCE_UPDATE: 'false' SHUFFLE_APP_HOTLOAD_FOLDER: /shuffle-apps SHUFFLE_DEFAULT_APIKEY: zaCELgL.0imfnc8mVLWwsAawjYr4Rx-Af50DDqtlx SHUFFLE_DEFAULT_PASSWORD: Fr1kky1sN0t@D0g SHUFFLE_DEFAULT_USERNAME: admin SHUFFLE_DOWNLOAD_AUTH_BRANCH: '' SHUFFLE_FILE_LOCATION: /shuffle-files ports: - 5001:5001 volumes: - /var/run/docker.sock:/var/run/docker.sock - /mnt/docker_data/SOAR/shuffle_data/shuffle-demo/shuffle-apps:/shuffle-apps - /mnt/docker_data/SOAR/shuffle_data/shuffle-demo/shuffle-files:/shuffle-files networks: - shuffle logging: driver: json-file deploy: replicas: 3 database: image: frikky/shuffle:database ports: - 30002:8000 volumes: - /mnt/docker_data/SOAR/shuffle_data/shuffle-demo/shuffle-database:/etc/shuffle networks: - shuffle logging: driver: json-file deploy: replicas: 1 frontend: image: ghcr.io/frikky/shuffle-frontend:0.8.74 environment: BACKEND_HOSTNAME: shuffle-backend ports: - 3001:80 - 3443:443 networks: - shuffle logging: driver: json-file deploy: replicas: 3 orborus: image: ghcr.io/frikky/shuffle-orborus:0.8.73 environment: BASE_URL: http://shuffle-backend:5001 CLEANUP: 'false' DOCKER_API_VERSION: '1.40' ENVIRONMENT_NAME: Shuffle HTTPS_PROXY: '' HTTP_PROXY: '' ORG_ID: Shuffle SHUFFLE_APP_SDK_VERSION: 0.8.77 SHUFFLE_BASE_IMAGE_NAME: frikky SHUFFLE_BASE_IMAGE_REGISTRY: ghcr.io SHUFFLE_BASE_IMAGE_TAG_SUFFIX: -0.8.60 SHUFFLE_ORBORUS_EXECUTION_TIMEOUT: '600' SHUFFLE_PASS_WORKER_PROXY: 'TRUE' SHUFFLE_WORKER_VERSION: 0.8.73 volumes: - /var/run/docker.sock:/var/run/docker.sock networks: - shuffle logging: driver: json-file deploy: replicas: 3 networks: shuffle: driver: overlay Setup data locations # This could be made as a command but I like to run first and echo instead of the \"mkdir -p\" to be sure I didn't made a mistake. # grep \"/mnt/docker_data\" /mnt/configuration_data/compose_files/SOAR/shuffle-stack.yml | awk -F \"- \" '{print $2'} | awk -F \":\" '{ system(\"mkdir -p \"$1\"\") }' Deploy Shuffle stack # Deploy the Shuffle stack by running docker stack deploy -c <path -to-docker-compose.yml> shuffle Log into your new instance at any nodes on port https://node:3443. Note # Have you may have seen, all except database have a replica set to 3. This is done so we don't create a messy mess on DB if writing are intented from different shuffle-database container at the same time on the same value which will lead to databse corruption. Anyway, this container is up in 7 second in case of failure of the node ^^ . App gonna be slow to run on it's first usage on all new nodes where Orborus is going to use the base image for the first time. As swarm distribute request around all replicas, sometime request gonna be fast as the node already run the image and sometime not. This all Replica and Clustering of Shuffle is not yet production ready as it is not yet properly implemented. I recommend using only one database and one Orborus for now.","title":"Shuffle"},{"location":"3-nodes-swarm/DockerSwarm/Stacks/Shuffler/#shuffle","text":"Shuffle is an Open Source SOAR I really appreciate as it does focus on CyberSecurity. To know more about it go there: https://medium.com/shuffle-automation Or there : Official Website Hi Frikky !!! Hoipefully, you will appreciate what you are seing here ^^","title":"Shuffle"},{"location":"3-nodes-swarm/DockerSwarm/Stacks/Shuffler/#preparaton","text":"","title":"Preparaton"},{"location":"3-nodes-swarm/DockerSwarm/Stacks/Shuffler/#setup-data-locations","text":"","title":"Setup data locations"},{"location":"3-nodes-swarm/DockerSwarm/Stacks/Shuffler/#setup-docker-swarm","text":"Deploying Portainer and the Portainer Agent to manage a Swarm cluster is easy! You can directly deploy Portainer as a service in your Docker cluster. Note that this method will automatically deploy a single instance of the Portainer Server, and deploy the Portainer Agent as a global service on every node in your cluster. # mkdir -p /mnt/configuration_data/compose_files/SOAR","title":"Setup Docker Swarm"},{"location":"3-nodes-swarm/DockerSwarm/Stacks/Shuffler/#customisation","text":"At the time of this writing I may be the only one shufflying around with swarm :p So there is not yet a stack ready compose file. Let's create one /mnt/configuration_data/compose_files/SOAR/shuffle.stack.yml version: '3.3' services: backend: image: ghcr.io/frikky/shuffle-backend:0.8.74 environment: DATASTORE_EMULATOR_HOST: shuffle-database:8000 HTTPS_PROXY: '' HTTP_PROXY: '' ORG_ID: Shuffle SHUFFLE_APP_DOWNLOAD_LOCATION: https://github.com/frikky/shuffle-apps SHUFFLE_APP_FORCE_UPDATE: 'false' SHUFFLE_APP_HOTLOAD_FOLDER: /shuffle-apps SHUFFLE_DEFAULT_APIKEY: zaCELgL.0imfnc8mVLWwsAawjYr4Rx-Af50DDqtlx SHUFFLE_DEFAULT_PASSWORD: Fr1kky1sN0t@D0g SHUFFLE_DEFAULT_USERNAME: admin SHUFFLE_DOWNLOAD_AUTH_BRANCH: '' SHUFFLE_FILE_LOCATION: /shuffle-files ports: - 5001:5001 volumes: - /var/run/docker.sock:/var/run/docker.sock - /mnt/docker_data/SOAR/shuffle_data/shuffle-demo/shuffle-apps:/shuffle-apps - /mnt/docker_data/SOAR/shuffle_data/shuffle-demo/shuffle-files:/shuffle-files networks: - shuffle logging: driver: json-file deploy: replicas: 3 database: image: frikky/shuffle:database ports: - 30002:8000 volumes: - /mnt/docker_data/SOAR/shuffle_data/shuffle-demo/shuffle-database:/etc/shuffle networks: - shuffle logging: driver: json-file deploy: replicas: 1 frontend: image: ghcr.io/frikky/shuffle-frontend:0.8.74 environment: BACKEND_HOSTNAME: shuffle-backend ports: - 3001:80 - 3443:443 networks: - shuffle logging: driver: json-file deploy: replicas: 3 orborus: image: ghcr.io/frikky/shuffle-orborus:0.8.73 environment: BASE_URL: http://shuffle-backend:5001 CLEANUP: 'false' DOCKER_API_VERSION: '1.40' ENVIRONMENT_NAME: Shuffle HTTPS_PROXY: '' HTTP_PROXY: '' ORG_ID: Shuffle SHUFFLE_APP_SDK_VERSION: 0.8.77 SHUFFLE_BASE_IMAGE_NAME: frikky SHUFFLE_BASE_IMAGE_REGISTRY: ghcr.io SHUFFLE_BASE_IMAGE_TAG_SUFFIX: -0.8.60 SHUFFLE_ORBORUS_EXECUTION_TIMEOUT: '600' SHUFFLE_PASS_WORKER_PROXY: 'TRUE' SHUFFLE_WORKER_VERSION: 0.8.73 volumes: - /var/run/docker.sock:/var/run/docker.sock networks: - shuffle logging: driver: json-file deploy: replicas: 3 networks: shuffle: driver: overlay","title":"Customisation"},{"location":"3-nodes-swarm/DockerSwarm/Stacks/Shuffler/#setup-data-locations_1","text":"This could be made as a command but I like to run first and echo instead of the \"mkdir -p\" to be sure I didn't made a mistake. # grep \"/mnt/docker_data\" /mnt/configuration_data/compose_files/SOAR/shuffle-stack.yml | awk -F \"- \" '{print $2'} | awk -F \":\" '{ system(\"mkdir -p \"$1\"\") }'","title":"Setup data locations"},{"location":"3-nodes-swarm/DockerSwarm/Stacks/Shuffler/#deploy-shuffle-stack","text":"Deploy the Shuffle stack by running docker stack deploy -c <path -to-docker-compose.yml> shuffle Log into your new instance at any nodes on port https://node:3443.","title":"Deploy Shuffle stack"},{"location":"3-nodes-swarm/DockerSwarm/Stacks/Shuffler/#note","text":"Have you may have seen, all except database have a replica set to 3. This is done so we don't create a messy mess on DB if writing are intented from different shuffle-database container at the same time on the same value which will lead to databse corruption. Anyway, this container is up in 7 second in case of failure of the node ^^ . App gonna be slow to run on it's first usage on all new nodes where Orborus is going to use the base image for the first time. As swarm distribute request around all replicas, sometime request gonna be fast as the node already run the image and sometime not. This all Replica and Clustering of Shuffle is not yet production ready as it is not yet properly implemented. I recommend using only one database and one Orborus for now.","title":"Note"},{"location":"3-nodes-swarm/GlusterFS/GlusterFS/","text":"Installing GlusterFS Server # Adding Gluster Repository # # dnf install centos-release-gluster` Installing GlusterFS Server # # dnf install glusterfs-server A bit of simplification for management. # Generate ssh-key # # ssh-keygen -t ed25519 Push ssh-key to all nodes # # ssh-copy-id root@swarm2 # ssh-copy-id root@swarm3 This should be done on all nodes. Stop firewall # I highly doesn't recommend to stop the firewall but I don't want also that you will get frustrated because of it. So go look how to stop firewalld on CentOS using your favorite search engine. Configure GlusterFS # generate a private key for each node # # openssl genrsa -out /etc/ssl/glusterfs.key 4096` generate a signed certificate for each node # # openssl req -new -x509 -key /etc/ssl/glusterfs.key -subj \"/CN=`hostname -f`\" -out /etc/ssl/glusterfs.pem hostname -f : for full fqdn (swarm1.lab.local) hostname -s : for short version (swarm1) This is important to understand what are you going to use on all the nodes as it's going to be used to identify the allowed host to mount Gluster's volume. Enable and start service # # systemctl enable glusterd --now Peer nodes # From swarm1 run : # gluster peer probe swarm2 # gluster peer probe swarm3 Verify peers: # gluster peer status Number of Peers: 2 Hostname: swarm2 Uuid: 1085c1ff-6b79-4021-b6d4-93db50b8709a State: Peer in Cluster (Connected) Hostname: swarm3 Uuid: 68525dfd-e91c-4563-9e16-76131025dc68 State: Peer in Cluster (Connected) Create GlusterFS Volumes # We are going to create two separate volumes. One for the different compose files and on for the env volumes. We could have made only one GlusterFS volume for both but I like to separate elements. One thing you have to keep in mind, GlusterFS use bricks in between nodes that are folder. Do not write directly in it but on a mount of it. Compose and env Volumes # We gonna start by creating the brick # mkdir -p /var/glusterfs/no-direct-write-here/vol_configuration/brick1 # ssh root@swarm2 mkdir -p /var/glusterfs/no-direct-write-here/vol_configuration/brick1 # ssh root@swarm3 mkdir -p /var/glusterfs/no-direct-write-here/vol_configuration/brick1 Create a volume from it. # gluster volume create vol_configuration replica 3 transport tcp swarm{1..3}:/var/glusterfs/no-direct-write-here/vol_configuration/brick1 force volume create: vol_configuration: success: please start the volume to access data Let's activate tcp encryption. # gluster volume set vol_configuration client.ssl on volume set: success # gluster volume set vol_configuration server.ssl on volume set: success Time to allow our nodes to mount the volume as client and brick data as server. # gluster volume set vol_configuration auth.ssl-allow swarm1.lab.local,swarm2.lab.local,swarm3.lab.local volume set: success And now we start it. # gluster volume start vol_configuration volume start: vol_configuration: success Now we need to create a mount point for it. # mkdir /mnt/configuration_data/ # ssh root@swarm2 mkdir /mnt/configuration_data/ # ssh root@swarm3 mkdir /mnt/configuration_data/ And now we mount it. # mount -t glusterfs localhost:/vol_configuration /mnt/configuration_data # ssh root@swarm2 mount -t glusterfs localhost:/vol_configuration /mnt/configuration_data # ssh root@swarm3 mount -t glusterfs localhost:/vol_configuration /mnt/configuration_data We check this is working as it should: # touch /mnt/configuration_data/youpi # ssh root@swarm2 ls /mnt/configuration_data # ssh root@swarm3 ls /mnt/configuration_data youpi And that ssl is activated grep ssl /var/log/glusterfs/mnt-configuration_data.log We want to have it mounted on startup so we add this to /etc/fstab of each node: echo \"localhost:/vol_configuration /mnt/configuration_data glusterfs defaults 0 0\" >> /etc/fstab Docker Data Volumes # Same as above but with the brick made here : /var/glusterfs/no-direct-write-here/vol_docker/brick1 And mountpoint: /mnt/docker_data/ Troubleshoot no GlusterFS mount on startup # I encoutered issue for the glusterFS volume to be mounted as startup as when the fstab is read by the system, glusterd is not yet running. The solution is to translate it in systemd-mount unit. # mkdir /etc/systemd/system/glusterfs.mount.d/ # ssh root@swarm2 mkdir /etc/systemd/system/configuration_data.mount.d/ # ssh root@swarm3 mkdir /etc/systemd/system/configuration_data.mount.d/ Official Documentation : https://docs.gluster.org/en/latest/","title":"Installing GlusterFS Server"},{"location":"3-nodes-swarm/GlusterFS/GlusterFS/#installing-glusterfs-server","text":"","title":"Installing GlusterFS Server"},{"location":"3-nodes-swarm/GlusterFS/GlusterFS/#adding-gluster-repository","text":"# dnf install centos-release-gluster`","title":"Adding Gluster Repository"},{"location":"3-nodes-swarm/GlusterFS/GlusterFS/#installing-glusterfs-server_1","text":"# dnf install glusterfs-server","title":"Installing GlusterFS Server"},{"location":"3-nodes-swarm/GlusterFS/GlusterFS/#a-bit-of-simplification-for-management","text":"","title":"A bit of simplification for management."},{"location":"3-nodes-swarm/GlusterFS/GlusterFS/#generate-ssh-key","text":"# ssh-keygen -t ed25519","title":"Generate ssh-key"},{"location":"3-nodes-swarm/GlusterFS/GlusterFS/#push-ssh-key-to-all-nodes","text":"# ssh-copy-id root@swarm2 # ssh-copy-id root@swarm3 This should be done on all nodes.","title":"Push ssh-key to all nodes"},{"location":"3-nodes-swarm/GlusterFS/GlusterFS/#stop-firewall","text":"I highly doesn't recommend to stop the firewall but I don't want also that you will get frustrated because of it. So go look how to stop firewalld on CentOS using your favorite search engine.","title":"Stop firewall"},{"location":"3-nodes-swarm/GlusterFS/GlusterFS/#configure-glusterfs","text":"","title":"Configure GlusterFS"},{"location":"3-nodes-swarm/GlusterFS/GlusterFS/#generate-a-private-key-for-each-node","text":"# openssl genrsa -out /etc/ssl/glusterfs.key 4096`","title":"generate a private key for each node"},{"location":"3-nodes-swarm/GlusterFS/GlusterFS/#generate-a-signed-certificate-for-each-node","text":"# openssl req -new -x509 -key /etc/ssl/glusterfs.key -subj \"/CN=`hostname -f`\" -out /etc/ssl/glusterfs.pem hostname -f : for full fqdn (swarm1.lab.local) hostname -s : for short version (swarm1) This is important to understand what are you going to use on all the nodes as it's going to be used to identify the allowed host to mount Gluster's volume.","title":"generate a signed certificate for each node"},{"location":"3-nodes-swarm/GlusterFS/GlusterFS/#enable-and-start-service","text":"# systemctl enable glusterd --now","title":"Enable and start service"},{"location":"3-nodes-swarm/GlusterFS/GlusterFS/#peer-nodes","text":"From swarm1 run : # gluster peer probe swarm2 # gluster peer probe swarm3 Verify peers: # gluster peer status Number of Peers: 2 Hostname: swarm2 Uuid: 1085c1ff-6b79-4021-b6d4-93db50b8709a State: Peer in Cluster (Connected) Hostname: swarm3 Uuid: 68525dfd-e91c-4563-9e16-76131025dc68 State: Peer in Cluster (Connected)","title":"Peer nodes"},{"location":"3-nodes-swarm/GlusterFS/GlusterFS/#create-glusterfs-volumes","text":"We are going to create two separate volumes. One for the different compose files and on for the env volumes. We could have made only one GlusterFS volume for both but I like to separate elements. One thing you have to keep in mind, GlusterFS use bricks in between nodes that are folder. Do not write directly in it but on a mount of it.","title":"Create GlusterFS Volumes"},{"location":"3-nodes-swarm/GlusterFS/GlusterFS/#compose-and-env-volumes","text":"We gonna start by creating the brick # mkdir -p /var/glusterfs/no-direct-write-here/vol_configuration/brick1 # ssh root@swarm2 mkdir -p /var/glusterfs/no-direct-write-here/vol_configuration/brick1 # ssh root@swarm3 mkdir -p /var/glusterfs/no-direct-write-here/vol_configuration/brick1 Create a volume from it. # gluster volume create vol_configuration replica 3 transport tcp swarm{1..3}:/var/glusterfs/no-direct-write-here/vol_configuration/brick1 force volume create: vol_configuration: success: please start the volume to access data Let's activate tcp encryption. # gluster volume set vol_configuration client.ssl on volume set: success # gluster volume set vol_configuration server.ssl on volume set: success Time to allow our nodes to mount the volume as client and brick data as server. # gluster volume set vol_configuration auth.ssl-allow swarm1.lab.local,swarm2.lab.local,swarm3.lab.local volume set: success And now we start it. # gluster volume start vol_configuration volume start: vol_configuration: success Now we need to create a mount point for it. # mkdir /mnt/configuration_data/ # ssh root@swarm2 mkdir /mnt/configuration_data/ # ssh root@swarm3 mkdir /mnt/configuration_data/ And now we mount it. # mount -t glusterfs localhost:/vol_configuration /mnt/configuration_data # ssh root@swarm2 mount -t glusterfs localhost:/vol_configuration /mnt/configuration_data # ssh root@swarm3 mount -t glusterfs localhost:/vol_configuration /mnt/configuration_data We check this is working as it should: # touch /mnt/configuration_data/youpi # ssh root@swarm2 ls /mnt/configuration_data # ssh root@swarm3 ls /mnt/configuration_data youpi And that ssl is activated grep ssl /var/log/glusterfs/mnt-configuration_data.log We want to have it mounted on startup so we add this to /etc/fstab of each node: echo \"localhost:/vol_configuration /mnt/configuration_data glusterfs defaults 0 0\" >> /etc/fstab","title":"Compose and env Volumes"},{"location":"3-nodes-swarm/GlusterFS/GlusterFS/#docker-data-volumes","text":"Same as above but with the brick made here : /var/glusterfs/no-direct-write-here/vol_docker/brick1 And mountpoint: /mnt/docker_data/","title":"Docker Data Volumes"},{"location":"3-nodes-swarm/GlusterFS/GlusterFS/#troubleshoot-no-glusterfs-mount-on-startup","text":"I encoutered issue for the glusterFS volume to be mounted as startup as when the fstab is read by the system, glusterd is not yet running. The solution is to translate it in systemd-mount unit. # mkdir /etc/systemd/system/glusterfs.mount.d/ # ssh root@swarm2 mkdir /etc/systemd/system/configuration_data.mount.d/ # ssh root@swarm3 mkdir /etc/systemd/system/configuration_data.mount.d/ Official Documentation : https://docs.gluster.org/en/latest/","title":"Troubleshoot no GlusterFS mount on startup"}]}